### YamlMime:Course
title: Data Engineering on Microsoft Azure
metadata:
  title: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
  description: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
uid: course.dp-203t00
courseNumber: 'DP-203T00-A'
hoursToComplete: 96
iconUrl: /media/learn/certification/course.svg
skillsGained:
- skill: Azureのデータエンジニアリングワークロードのコンピューティングとストレージのオプションを調べる
- skill: サーバーレスSQLプールを使用してインタラクティブクエリを実行する
- skill: Azure Databricksでデータの探索と変換を実行する
- skill: Apache Sparkを使ってデータを探索、変換、データウェアハウスにロード
- skill: データを取り込み、データウェアハウスにロードします
- skill: Azure DataFactoryまたはAzure Synapseパイプラインを使用してデータを変換する
- skill: ノートブックのデータをAzure Data FactoryまたはAzure Synapseパイプラインと統合する
- skill: Azure Synapse Linkを使用したHybrid Transactional Analytical Processing HTAP）のサポート
- skill: Azure Synapse Analyticsを使用してエンドツーエンドのセキュリティを実行します
- skill: StreamAnalyticsを使用してリアルタイムのストリーム処理を実行します
- skill: Event HubsとAzure Databricksを使用してストリーム処理ソリューションを作成する
learningPartnersLink: /learn/certifications/partners
locales:
- en
levels:
- intermediate
roles:
- data-engineer
products:
- azure
exams:
- uid: exam.dp-203
summary: |-
  このコースでは、Azureデータプラットフォームテクノロジを使用したバッチおよびリアルタイムの分析ソリューションの操作に関連するデータエンジニアリングについて学習します。受講者は、分析ソリューションの構築に使用されるコアコンピューティングおよびストレージテクノロジーを理解することから始めます。受講者は、データレイク内のファイルに保存されているデータをインタラクティブに探索する方法を学びます。彼らは、Azure  Synapse AnalyticsまたはAzure DatabricksにあるApache Spark機能を使用してデータを読み込むために使用できるさまざまな取り込み手法、またはAzure Data FactoryまたはAzure Synapseパイプラインを使用して取り込む方法を学習します。受講者はまた、データの取り込みに使用されるのと同じテクノロジーを使用してデータを変換するさまざまな方法を学びます。彼らは、データが保管中または転送中に保護されることを保証するためにセキュリティを実装することの重要性を理解します。次に、受講者は、リアルタイム分析システムを作成してリアルタイム分析ソリューションを作成する方法を示します。

  #### オーディエンスプロフィール
  このコースの主な対象者は、Microsoft Azureに存在するデータプラットフォームテクノロジを使用してデータエンジニアリングと分析ソリューションを構築する方法について学びたいデータプロフェッショナル、データアーキテクト、およびビジネスインテリジェンスプロフェッショナルです。このコースの二次対象者は、Microsoft Azure上に構築された分析ソリューションを使用するデータアナリストおよびデータサイエンティストです。
prerequisitesSection: |-
  成功する受講者は、cloud コンピューティングとコアデータの概念に関する知識と、データソリューションに関する専門的な経験を持った状態でこのコースを開始します。
  
  具体的に下記の完了&#58;
  - AZ-900 - Azure Fundamentals
  - DP-900 - Microsoft Azure Data Fundamentals
outlineSection: |-
  ### モジュール 1&#58; データエンジニアリングワークロードのコンピューティングおよびストレージオプションの調査
  このモジュールでは、分析ワークロードを構築するデータエンジニアが利用できるAzureコンピューティングおよびストレージテクノロジーオプションの概要を説明致します。このモジュールでは、data lakeを構造化し、探索、ストリーミング、およびバッチワークロード用にファイルを最適化する方法を説明致します。受講者は、バッチおよびストリーム処理を通じてファイルを変換するときに、data lakeをデータリファインメントのレベルに編成する方法を学習して頂きます。次に、CSV、JSON、Parquetファイルなどのデータセットにインデックスを作成し、それらを潜在的なクエリとワークロードの高速化に使用する方法を学習して頂きます。
  #### レッスン
  - Azure Synapse Analyticsの概要
  - Azure Databricksについての説明
  - Azure Data Lakeストレージの概要
  - Delta Lakeのアーキテクチャについての説明
  - Azure Stream Analyticsを使用してデータストリームの操作

  #### ラボ&#58; データエンジニアリングワークロードのコンピューティングおよびストレージオプションの調査
  * ストリーミングとバッチ処理を単一のパイプラインとの組み合わせ
  * データレイクをファイル変換のレベルに整理
  * クエリとワークロードを高速化するためのインデックスデータレイクストレージ
 
  このモジュールを完了すると、受講者は次のことができるようになります。
  - Azure Synapse Analyticsについての説明
  - Azure Databricksについての説明
  - Azure Data Lakeストレージについての説明
  - Delta Lake のアーキテクチャについての説明
  - Azure Stream Analyticsについての説明

  ### モジュール 2&#58;  Azure Synapse AnalyticsサーバーレスSQLプールを使用してインタラクティブクエリを実行
  このモジュールでは、Azure Synapse AnalyticsのサーバーレスSQLプールによって実行されるT-SQLステートメントを通じて、data lakeに格納されているファイルと外部ファイルソースを操作する方法を学習して頂きます。受講者は、data lakeに保存されているParquetファイルと、外部データストアに保存されているCSVファイルをクエリします。次に、Azure Active Directoryセキュリティグループを作成し、ロールベースのアクセス制御（RBAC）とアクセス制御リスト（ACL）を介してdata lake内のファイルへのアクセスを強制します。
  #### レッスン
  - Azure SynapseサーバーレスSQLプール機能の調査
  - Azure SynapseサーバーレスSQLプールを使用して湖のデータのクエリ
  - Azure SynapseサーバーレスSQLプールにメタデータオブジェクトの作成
  - Azure SynapseサーバーレスSQLプールでデータを保護してユーザーの管理
 
  #### ラボ&#58; サーバーレスSQLプールを使用してインタラクティブクエリの実行
  - サーバーレスSQLプールを使用してParquetデータをクエリ
  - ParquetおよびCSVファイルの外部テーブルの作成
  - サーバーレスSQLプールを使用してビューの作成
  - サーバーレスSQLプールを使用する場合、data lake内のデータへの安全なアクセス
  - ロールベースのアクセス制御（RBAC）とアクセス制御リストを使用してdata lakeのセキュリティの構成
 
  このモジュールを完了すると、受講者は次のことができるようになります。
  - Azure SynapseサーバーレスSQLプールの機能の理解
  - Azure SynapseサーバーレスSQLプールを使用してレイクのデータのクエリ
  - Azure SynapseサーバーレスSQLプールにメタデータオブジェクトの作成
  - Azure SynapseサーバーレスSQLプールでデータを保護してユーザーの管理

  ### モジュール 3: Azure Databricksでのデータの探索と変換

  このモジュールでは、さまざまなApache Spark DataFrameメソッドを使用して、Azure Databricksのデータを探索および変換する方法について説明します。受講者は、標準のDataFrameメソッドを実行してデータを探索および変換する方法を学習します。また、重複データの削除、日付/時刻値の操作、列の名前変更、データの集計など、より高度なタスクを実行する方法についても学習します。

  #### レッスン

  * Azure Databricksについての説明

  * Azure Databricksでのデータの読み取りと書き込み

  * Azure DatabricksでDataFrameの操作

  * Azure DatabricksでDataFramesの高度なメソッドの操作


  ####ラボ：Azure Databricksでのデータの探索と変換

  ####
  * Azure DatabricksのDataFrameを使用して、データを探索およびフィルタリング
  * 後続のクエリを高速化するためにDataFrameのキャッシュ
  * 重複データの削除
  * 日付/時刻の値の操作
  * DataFrame列を削除して名前を変更します
  * DataFrameに保存されているデータを集約

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Databricksについての説明

  * Azure Databricksでのデータの読み取りと書き込み

  * Azure DatabricksでDataFramesの操作

  * Azure DatabricksでDataFramesの高度なメソッドの操作


  ### モジュール 4: Apache Sparkを使用してデータを探索、変換、データウェアハウスにロード

  このモジュールでは、データレイクに格納されているデータを探索し、データを変換し、データをリレーショナルデータストアにロードする方法について説明します。受講者はの床とパルケJSONファイルを探索し、階層構造でJSONファイルをクエリして変換する手法を使用します。次に、受講者はApache Sparkを使用してデータをデータウェアハウスにロードし、データレイクのパルケデータを専用のSQLプールのデータと結合します。

  #### レッスン

  * Azure Synapse AnalyticsのApache Sparkを使用したビッグデータエンジニアリングを理解する

  * Azure Synapse AnalyticsでApache Sparkノートブックを使用してデータを取り込む

  * Azure Synapse AnalyticsのApache SparkプールのDataFrameを使用してデータを変換する

  * SQLプールとApache SparkプールをAzure Synapse Analyticsに統合する


  #### ラボ：Apache Sparkを使用して、データを探索、変換、およびデータウェアハウスにロード

  ####
  * Synapse Studioでデータ探索の実行
  * Azure Synapse AnalyticsでSparkノートブックを使用してデータの取り込み
  * Azure Synapse AnalyticsのSparkプールのDataFrameを使用してデータの変換
  * SQLプールとSparkプールをAzure Synapse Analyticsに統合

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Synapse AnalyticsでApache Sparkを使用したビッグデータエンジニアリングについての説明

  * Azure Synapse AnalyticsでApache Sparkノートブックを使用してデータの取り込み

  * Azure Synapse AnalyticsのApache Sparkプールのデータフレームを使用してデータの変換

  * SQLプールとApache SparkプールをAzure Synapse Analyticsに統合
  
  ### モジュール 5: データを取り込んでデータウェアハウスにロード

  このモジュールでは、T-SQLスクリプトとSynapse Analytics統合パイプラインを介してデータウェアハウスにデータを取り込む方法を受講者にお伝えします。受講者は、PolyBaseを使用してSynapse専用SQLプールにデータをロードし、T-SQLを使用してCOPYする方法を学習します。また、ペタバイト規模のデータを取り込むために、Azure Synapse Pipelinesでコピーアクティビティとともにワークロード管理を使用する方法も学習します。

  #### レッスン

  * Azure Synapse Analyticsでデータ読み込みのベストプラクティスの使用

  * Azure Data Factoryによるペタバイト規模の取り込み


  #### ラボ：データを取り込んでデータウェアハウスにロード

  ####
  * Azure Synapse Pipelinesを使用してペタバイト規模の取り込みの実行
  * PolyBaseでデータをインポートし、T-SQLを使用してCOPY
  * Azure Synapse Analyticsでデータ読み込みのベストプラクティスの使用

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Synapse Analyticsでデータ読み込みのベストプラクティスの使用

  * Azure Data Factoryによるペタバイト規模の取り込み


  ### モジュール 6: Azure Data FactoryまたはAzure Synapse Pipelinesを使用してデータの変換

  このモジュールでは、データ統合パイプラインを構築して複数のデータソースから取り込み、マッピングデータフローを使用してデータを変換し、1つ以上のデータシンクにデータを移動する方法を学習します。

  #### レッスン

  * Azure Data FactoryまたはAzure Synapse Pipelinesとのデータ統合

  * Azure Data FactoryまたはAzure Synapse Pipelinesを使用した大規模なコードフリー変換


  #### ラボ：Azure Data FactoryまたはAzure Synapse Pipelinesを使用してデータの変換

  ####
  * Azure Synapse Pipelinesを使用して、コードフリーの変換を大規模に実行
  * フォーマットが不十分なCSVファイルをインポートするためのデータパイプラインの作成
  * マッピングデータフローの作成

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Data Factoryとのデータ統合の実行

  * Azure Data Factoryを使用して大規模なコードフリー変換の実行
  
  ### モジュール 7: Azure Synapse Pipelinesでのデータの移動と変換の調整

  このモジュールでは、リンクされたサービスを作成する方法と、Azure Synapse Pipelinesでノートブックを使用してデータの移動と変換の調整方法を学習します。

  #### レッスン

  * Azure Data Factoryでデータの移動と変換の調整


  #### ラボ：Azure Synapse Pipelinesでのデータの移動と変換の調整

  ####
  * ノートブックのデータをAzureData FactoryまたはAzure Synapse Pipelinesと統合する

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Synapse Pipelinesでのデータの移動と変換の調整


  ### モジュール 8: Azure Synapse Analyticsを使用したエンドツーエンドのセキュリティ

  このモジュールでは、Synapse Analyticsワークスペースとそのサポートインフラストラクチャを保護する方法を学習します。受講者は、SQL Active Directory Adminを観察し、IPファイアウォールルールを管理し、Azure Key Vaultでシークレットを管理し、KeyVaultにリンクされたサービスとパイプラインアクティビティを介してそれらのシークレットにアクセスします。受講者は、専用のSQLプールを使用するときに、列レベルのセキュリティ、行レベルのセキュリティ、およびdynamicデータマスキングを実装する方法を理解します。

  #### レッスン

  * Azure Synapse Analyticsでデータウェアハウスの保護

  * Azure KeyVaultでシークレットを構成および管理

  * 機密データのコンプライアンス管理の実装


  #### ラボ：Azure Synapse Analyticsを使用したエンドツーエンドのセキュリティ

  ####
  *インフラストラクチャをサポートするセキュアなAzureSynapse Analytics
  * Azure Synapse Analyticsワークスペースとマネージドサービスの保護
  * Azure Synapse Analyticsワークスペースデータの保護

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Synapse Analyticsでデータウェアハウスの保護

  * Azure KeyVaultでシークレットを構成および管理

  *機密データのコンプライアンス管理の実装
  
  ### モジュール 9: Azure Synapse Linkを使用したHybrid Transactional Analytical Processing (HTAP)のサポート

  このモジュールでは、Azure Synapse LinkによってAzure Cosmos　DBアカウントをSynapseワークスペースにシームレスに接続する方法を学習します。受講者は、Synapseリンクを有効にして構成する方法を理解し、次にApache SparkとSQLサーバーレスを使用してAzure Cosmos　DB分析ストアにクエリを実行する方法を理解します。

  #### レッスン

  * Azure Synapse Analyticsを使用してトランザクションと分析のハイブリッド処理の設計

  * Azure Cosmos　DBを使用してAzure Synapse Linkの構成

  * Apache Sparkプールを使用してAzure Cosmos　DBにクエリの実行

  * サーバーレスSQLプールを使用してAzure Cosmos　DBをクエリ


  #### ラボ：Azure Synapse Linkを使用したHybrid Transactional Analytical Processing (HTAP)のサポート

  ####
  * Azure Cosmos　DBを使用してAzure Synapse Linkの構成
  * Synapse Analytics用のApache Sparkを使用してAzure Cosmos DBをクエリ
  * Azure Synapse AnalyticsのサーバーレスSQLプールを使用してAzure Cosmos　DBにクエリを実行

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Synapse Analyticsを使用してトランザクションと分析のハイブリッド処理の設計

  * Azure Cosmos　DBを使用してAzure Synapse Linkの構成

  * Azure Synapse Analytics用のApache Sparkを使用してAzure Cosmos DBをクエリ

  * Azure Synapse Analytics用のSQLサーバーレスを使用してAzure Cosmos DBをクエリ

  ### モジュール 10: Stream Analyticsを使用したリアルタイムストリーム処理

  このモジュールでは、受講者はAzure Stream Analyticsを使用してストリーミングデータを処理する方法を学習します。受講者は、車両のテレメトリデータをEvent Hubsに取り込み、Azure Stream Analyticsのさまざまなウィンドウ関数を使用して、そのデータをリアルタイムで処理します。データはAzure Synapse Analyticsに出力されます。最後に、受講者は、スループットを向上させるためにStream Analyticsジョブをスケーリングする方法を学習します。

  #### レッスン

  * Azure Event Hubsを使用してBig Dataアプリケーションの信頼性の高いメッセージングを有効化

  * Azure Stream Analyticsを使用してデータストリームの操作

  * Azure Stream Analyticsを使用してデータストリームの取り込み


  #### ラボ：Stream Analyticsを使用したリアルタイムストリーム処理

  ####
  * Stream Analyticsを使用して、Event Hubsからのリアルタイムデータの処理
  * Stream Analyticsウィンドウ関数を使用して、集計を作成し、Synapse Analyticsに出力
  * Azure Stream Analyticsジョブをスケーリングして、パーティショニングを通じてスループットの向上

  * 並列化を最適化するためにストリーム入力を再パーティション化

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Event Hubsを使用してBig dataアプリケーションの信頼性の高いメッセージングの有効化

  * Azure Stream Analyticsを使用してデータストリームの操作

  * Azure Stream Analyticsを使用してデータストリームの取り込み
  
  ### モジュール 11: Event HubsとAzure Databrickを使用してストリーム処理ソリューションの作成

  このモジュールでは、Azure DatabrickのEvent HubsとSpark Structured Streamingを使用してストリーミングデータを大規模に取り込んで処理する方法を学習します。受講者は、Structured Streamingの主な機能と使用法を学びます。受講者は、スライドウィンドウを実装してデータのチャンクを集約し、透かしを適用して古いデータを削除します。最後に、受講者はEvent Hubsに接続して、ストリームの読み取りと書き込みを行います。

  #### レッスン

  * Azure DatabrickStructured Streamingでストリーミングデータの処理


  #### ラボ：Event HubsとAzure Databrickを使用してストリーム処理ソリューションの作成

  ####
  * Structured Streamingの主な機能と使用法の模索
  * ファイルからデータをストリーミングし、分散ファイルシステムに書き出し
  * スライディングウィンドウを使用して、すべてのデータではなくデータのチャンクを集約します
  * 古いデータを削除するために透かしの適用
  * Event Hubsの読み取りおよび書き込みストリームに接続

  このモジュールを完了すると、受講者は次のことができるようになります。

  * Azure Databrick Structured Streamingでストリーミングデータの処理
